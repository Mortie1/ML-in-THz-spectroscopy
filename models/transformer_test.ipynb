{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TORCH_USE_CUDA_DSA=1\n",
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env TORCH_USE_CUDA_DSA=1\n",
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import Optimizer, Adam\n",
    "from torch.optim.lr_scheduler import LRScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1000</th>\n",
       "      <th>element_1</th>\n",
       "      <th>element_2</th>\n",
       "      <th>element_3</th>\n",
       "      <th>element_1_ratio</th>\n",
       "      <th>element_2_ratio</th>\n",
       "      <th>element_3_ratio</th>\n",
       "      <th>temp</th>\n",
       "      <th>pressure</th>\n",
       "      <th>air_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51976</th>\n",
       "      <td>1.429725e-20</td>\n",
       "      <td>3.325318e-20</td>\n",
       "      <td>1.513897e-20</td>\n",
       "      <td>1.119836e-21</td>\n",
       "      <td>1.209848e-21</td>\n",
       "      <td>2.024112e-21</td>\n",
       "      <td>7.172782e-21</td>\n",
       "      <td>4.953834e-21</td>\n",
       "      <td>1.539859e-21</td>\n",
       "      <td>1.285451e-21</td>\n",
       "      <td>...</td>\n",
       "      <td>9.105786e-25</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0.136030</td>\n",
       "      <td>0.262144</td>\n",
       "      <td>0.601825</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18970</th>\n",
       "      <td>5.940243e-23</td>\n",
       "      <td>7.336601e-23</td>\n",
       "      <td>9.720283e-23</td>\n",
       "      <td>1.447083e-22</td>\n",
       "      <td>2.680262e-22</td>\n",
       "      <td>8.343595e-22</td>\n",
       "      <td>1.010416e-20</td>\n",
       "      <td>6.042984e-21</td>\n",
       "      <td>7.479574e-22</td>\n",
       "      <td>3.643073e-22</td>\n",
       "      <td>...</td>\n",
       "      <td>1.465311e-22</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>22</td>\n",
       "      <td>0.188355</td>\n",
       "      <td>0.316809</td>\n",
       "      <td>0.494835</td>\n",
       "      <td>283.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30497</th>\n",
       "      <td>1.193615e-20</td>\n",
       "      <td>6.945339e-21</td>\n",
       "      <td>6.543001e-22</td>\n",
       "      <td>2.529143e-22</td>\n",
       "      <td>1.749403e-22</td>\n",
       "      <td>3.243140e-22</td>\n",
       "      <td>3.550860e-22</td>\n",
       "      <td>1.091960e-22</td>\n",
       "      <td>9.629268e-23</td>\n",
       "      <td>1.882503e-22</td>\n",
       "      <td>...</td>\n",
       "      <td>7.445923e-23</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>19</td>\n",
       "      <td>0.444071</td>\n",
       "      <td>0.477905</td>\n",
       "      <td>0.078024</td>\n",
       "      <td>323.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30356</th>\n",
       "      <td>1.624151e-20</td>\n",
       "      <td>5.577240e-21</td>\n",
       "      <td>9.267746e-22</td>\n",
       "      <td>2.168774e-21</td>\n",
       "      <td>5.549700e-21</td>\n",
       "      <td>4.163047e-21</td>\n",
       "      <td>1.670818e-21</td>\n",
       "      <td>8.912111e-22</td>\n",
       "      <td>8.374945e-22</td>\n",
       "      <td>1.444200e-21</td>\n",
       "      <td>...</td>\n",
       "      <td>3.604447e-22</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>24</td>\n",
       "      <td>0.509421</td>\n",
       "      <td>0.224513</td>\n",
       "      <td>0.266066</td>\n",
       "      <td>323.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140548</th>\n",
       "      <td>2.003258e-21</td>\n",
       "      <td>1.077312e-21</td>\n",
       "      <td>3.272797e-22</td>\n",
       "      <td>1.452913e-22</td>\n",
       "      <td>9.167639e-23</td>\n",
       "      <td>6.963908e-23</td>\n",
       "      <td>5.832702e-23</td>\n",
       "      <td>5.251748e-23</td>\n",
       "      <td>4.962818e-23</td>\n",
       "      <td>4.851140e-23</td>\n",
       "      <td>...</td>\n",
       "      <td>9.615524e-22</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>18</td>\n",
       "      <td>0.227958</td>\n",
       "      <td>0.482563</td>\n",
       "      <td>0.289478</td>\n",
       "      <td>263.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218031</th>\n",
       "      <td>3.535618e-22</td>\n",
       "      <td>4.722553e-22</td>\n",
       "      <td>4.692500e-22</td>\n",
       "      <td>5.307244e-22</td>\n",
       "      <td>6.048017e-22</td>\n",
       "      <td>6.291295e-22</td>\n",
       "      <td>6.453254e-22</td>\n",
       "      <td>6.485575e-22</td>\n",
       "      <td>7.700791e-22</td>\n",
       "      <td>1.061828e-21</td>\n",
       "      <td>...</td>\n",
       "      <td>8.640137e-25</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.530767</td>\n",
       "      <td>0.469233</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>323.0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57587</th>\n",
       "      <td>9.397569e-22</td>\n",
       "      <td>1.173034e-21</td>\n",
       "      <td>2.279960e-21</td>\n",
       "      <td>8.301202e-22</td>\n",
       "      <td>8.418463e-22</td>\n",
       "      <td>9.303921e-22</td>\n",
       "      <td>1.093095e-21</td>\n",
       "      <td>2.257390e-21</td>\n",
       "      <td>3.849821e-21</td>\n",
       "      <td>3.221007e-21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.020158e-21</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "      <td>18</td>\n",
       "      <td>0.600135</td>\n",
       "      <td>0.375171</td>\n",
       "      <td>0.024694</td>\n",
       "      <td>303.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254241</th>\n",
       "      <td>7.204798e-22</td>\n",
       "      <td>1.141918e-21</td>\n",
       "      <td>2.021069e-21</td>\n",
       "      <td>3.898292e-21</td>\n",
       "      <td>4.167931e-21</td>\n",
       "      <td>3.322392e-21</td>\n",
       "      <td>2.260052e-21</td>\n",
       "      <td>1.356805e-21</td>\n",
       "      <td>9.869838e-22</td>\n",
       "      <td>1.119172e-21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.174975e-22</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>0.273032</td>\n",
       "      <td>0.469203</td>\n",
       "      <td>0.257765</td>\n",
       "      <td>293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30894</th>\n",
       "      <td>4.030195e-22</td>\n",
       "      <td>5.592868e-22</td>\n",
       "      <td>9.234086e-22</td>\n",
       "      <td>2.112966e-21</td>\n",
       "      <td>5.189306e-21</td>\n",
       "      <td>3.964872e-21</td>\n",
       "      <td>1.755474e-21</td>\n",
       "      <td>1.090197e-21</td>\n",
       "      <td>1.088081e-21</td>\n",
       "      <td>1.695364e-21</td>\n",
       "      <td>...</td>\n",
       "      <td>1.690917e-23</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>24</td>\n",
       "      <td>0.375711</td>\n",
       "      <td>0.384662</td>\n",
       "      <td>0.239627</td>\n",
       "      <td>323.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32552</th>\n",
       "      <td>5.608307e-21</td>\n",
       "      <td>5.375661e-21</td>\n",
       "      <td>3.065098e-21</td>\n",
       "      <td>2.121334e-20</td>\n",
       "      <td>1.853282e-20</td>\n",
       "      <td>1.564238e-21</td>\n",
       "      <td>8.492103e-22</td>\n",
       "      <td>1.319094e-21</td>\n",
       "      <td>6.949287e-22</td>\n",
       "      <td>1.153705e-21</td>\n",
       "      <td>...</td>\n",
       "      <td>7.678208e-24</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>20</td>\n",
       "      <td>0.296077</td>\n",
       "      <td>0.303199</td>\n",
       "      <td>0.400723</td>\n",
       "      <td>253.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131079 rows × 1010 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0             1             2             3             4  \\\n",
       "51976   1.429725e-20  3.325318e-20  1.513897e-20  1.119836e-21  1.209848e-21   \n",
       "18970   5.940243e-23  7.336601e-23  9.720283e-23  1.447083e-22  2.680262e-22   \n",
       "30497   1.193615e-20  6.945339e-21  6.543001e-22  2.529143e-22  1.749403e-22   \n",
       "30356   1.624151e-20  5.577240e-21  9.267746e-22  2.168774e-21  5.549700e-21   \n",
       "140548  2.003258e-21  1.077312e-21  3.272797e-22  1.452913e-22  9.167639e-23   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "218031  3.535618e-22  4.722553e-22  4.692500e-22  5.307244e-22  6.048017e-22   \n",
       "57587   9.397569e-22  1.173034e-21  2.279960e-21  8.301202e-22  8.418463e-22   \n",
       "254241  7.204798e-22  1.141918e-21  2.021069e-21  3.898292e-21  4.167931e-21   \n",
       "30894   4.030195e-22  5.592868e-22  9.234086e-22  2.112966e-21  5.189306e-21   \n",
       "32552   5.608307e-21  5.375661e-21  3.065098e-21  2.121334e-20  1.853282e-20   \n",
       "\n",
       "                   5             6             7             8             9  \\\n",
       "51976   2.024112e-21  7.172782e-21  4.953834e-21  1.539859e-21  1.285451e-21   \n",
       "18970   8.343595e-22  1.010416e-20  6.042984e-21  7.479574e-22  3.643073e-22   \n",
       "30497   3.243140e-22  3.550860e-22  1.091960e-22  9.629268e-23  1.882503e-22   \n",
       "30356   4.163047e-21  1.670818e-21  8.912111e-22  8.374945e-22  1.444200e-21   \n",
       "140548  6.963908e-23  5.832702e-23  5.251748e-23  4.962818e-23  4.851140e-23   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "218031  6.291295e-22  6.453254e-22  6.485575e-22  7.700791e-22  1.061828e-21   \n",
       "57587   9.303921e-22  1.093095e-21  2.257390e-21  3.849821e-21  3.221007e-21   \n",
       "254241  3.322392e-21  2.260052e-21  1.356805e-21  9.869838e-22  1.119172e-21   \n",
       "30894   3.964872e-21  1.755474e-21  1.090197e-21  1.088081e-21  1.695364e-21   \n",
       "32552   1.564238e-21  8.492103e-22  1.319094e-21  6.949287e-22  1.153705e-21   \n",
       "\n",
       "        ...          1000  element_1  element_2  element_3  element_1_ratio  \\\n",
       "51976   ...  9.105786e-25          9         12         22         0.136030   \n",
       "18970   ...  1.465311e-22          0         21         22         0.188355   \n",
       "30497   ...  7.445923e-23          5         16         19         0.444071   \n",
       "30356   ...  3.604447e-22          4         21         24         0.509421   \n",
       "140548  ...  9.615524e-22          4         13         18         0.227958   \n",
       "...     ...           ...        ...        ...        ...              ...   \n",
       "218031  ...  8.640137e-25          6          9         -1         0.530767   \n",
       "57587   ...  1.020158e-21         14         15         18         0.600135   \n",
       "254241  ...  1.174975e-22         10         18         20         0.273032   \n",
       "30894   ...  1.690917e-23          8         14         24         0.375711   \n",
       "32552   ...  7.678208e-24          2         16         20         0.296077   \n",
       "\n",
       "        element_2_ratio  element_3_ratio   temp  pressure  air_ratio  \n",
       "51976          0.262144         0.601825  283.0       0.2        0.6  \n",
       "18970          0.316809         0.494835  283.0       0.1        0.6  \n",
       "30497          0.477905         0.078024  323.0       0.1        0.6  \n",
       "30356          0.224513         0.266066  323.0       0.1        0.6  \n",
       "140548         0.482563         0.289478  263.0       0.5        0.6  \n",
       "...                 ...              ...    ...       ...        ...  \n",
       "218031         0.469233         0.000000  323.0       0.8        0.6  \n",
       "57587          0.375171         0.024694  303.0       0.2        0.6  \n",
       "254241         0.469203         0.257765  293.0       1.0        0.6  \n",
       "30894          0.384662         0.239627  323.0       0.1        0.6  \n",
       "32552          0.303199         0.400723  253.0       0.2        0.3  \n",
       "\n",
       "[131079 rows x 1010 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_pickle(\"test_proc.pkl\")\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomTransformerSpectraDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        device: str = \"cuda:0\",\n",
    "        chunk_size: int = 100,\n",
    "        normalize_elems: bool = False,\n",
    "    ) -> None:\n",
    "        self.data = data\n",
    "        self.elements = np.unique(\n",
    "            self.data[[\"element_1\", \"element_2\", \"element_3\"]].to_numpy()\n",
    "        )\n",
    "        self.chunk_size = chunk_size\n",
    "        self.air_ratios = data.air_ratio.to_numpy(dtype=np.float64)\n",
    "\n",
    "        self.spectras = torch.log(\n",
    "            torch.tensor(\n",
    "                self.data[[str(i) for i in range(1001)]].to_numpy(dtype=np.float64)\n",
    "            )\n",
    "        ).to(device)\n",
    "\n",
    "        self.ratios = torch.tensor(\n",
    "            self.data[\n",
    "                [\"element_1_ratio\", \"element_2_ratio\", \"element_3_ratio\"]\n",
    "            ].to_numpy(dtype=np.float64)\n",
    "        ).to(device)\n",
    "\n",
    "        if normalize_elems:\n",
    "            elems = np.unique(\n",
    "                self.data[[\"element_1\", \"element_2\", \"element_3\"]].to_numpy()\n",
    "            )\n",
    "            elem2id = {-1: -1}\n",
    "            idx = 0\n",
    "            for elem in elems:\n",
    "                if elem != -1:\n",
    "                    elem2id[elem] = idx\n",
    "                    idx += 1\n",
    "            self.data[\"element_1\"] = self.data[\"element_1\"].apply(lambda x: elem2id[x])\n",
    "            self.data[\"element_2\"] = self.data[\"element_2\"].apply(lambda x: elem2id[x])\n",
    "            self.data[\"element_3\"] = self.data[\"element_3\"].apply(lambda x: elem2id[x])\n",
    "\n",
    "        self.element_indices = self.data[\n",
    "            [\"element_1\", \"element_2\", \"element_3\"]\n",
    "        ].to_numpy(dtype=np.float64)\n",
    "\n",
    "        self.elements_distributions = torch.zeros(\n",
    "            [\n",
    "                len(self.data),\n",
    "                len(self.elements) - 1 if -1 in self.elements else len(self.elements),\n",
    "            ],\n",
    "            dtype=torch.float64,  # -1 as there is index that shows that there is no element\n",
    "        ).to(device)\n",
    "\n",
    "        for idx in range(len(self.data)):\n",
    "            indices = self.element_indices[idx, :]\n",
    "            indices = indices[indices != -1]\n",
    "\n",
    "            self.elements_distributions[idx, indices] = torch.where(self.ratios[idx][\n",
    "                range(indices.shape[0])\n",
    "            ] > 0, 1.0, 0.0).double()\n",
    "\n",
    "        self.elements_distributions = self.elements_distributions[\n",
    "            ~torch.isnan(self.spectras).any(dim=1)\n",
    "        ]\n",
    "        self.spectras = self.spectras[~torch.isnan(self.spectras).any(dim=1)]\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.spectras)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "        spectra = torch.stack(\n",
    "            self.spectras[idx, 1:].split(\n",
    "                self.chunk_size\n",
    "            )  # input will be split into chunks of self.chunk_size elements in them\n",
    "        )\n",
    "        elements_distribution = self.elements_distributions[idx]\n",
    "\n",
    "        return spectra, elements_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomTransformerSpectraDataset(test_df, chunk_size=250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=512,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float = 0.1, max_len: int = 1000):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        position = torch.arange(max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(1, max_len, d_model)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[batch_size, seq_len, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, : x.size(1), :]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class THzTransformer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        chunk_size: int = 250,\n",
    "        nhead: int = 2,\n",
    "        dim_feedforward: int = 1024,\n",
    "        dropout: float = 0.0,\n",
    "        batch_first: bool = True,\n",
    "        activation: str = \"relu\",\n",
    "        num_layers: int = 6,\n",
    "        linear_head_size: int = 1024,\n",
    "        output_size: int = 26,\n",
    "        device: str = \"cuda:0\",\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.cls_token_embedding = nn.Embedding(\n",
    "            num_embeddings=1, embedding_dim=chunk_size\n",
    "        )\n",
    "        self.batch_first = batch_first\n",
    "        encoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=chunk_size,\n",
    "            nhead=nhead,\n",
    "            dim_feedforward=dim_feedforward,\n",
    "            dropout=dropout,\n",
    "            batch_first=batch_first,\n",
    "            activation=activation,\n",
    "        )\n",
    "        self.positional_encoding = PositionalEncoding(\n",
    "            d_model=chunk_size, dropout=dropout\n",
    "        )\n",
    "        self.encoder = nn.TransformerEncoder(\n",
    "            encoder_layer=encoder_layer, num_layers=num_layers\n",
    "        )\n",
    "        self.linear_head = nn.Sequential(\n",
    "            nn.Linear(chunk_size, linear_head_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(linear_head_size, output_size),\n",
    "        )\n",
    "        self.cls_token_index = torch.tensor([0]).to(device)\n",
    "\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def init_weights(self) -> None:\n",
    "        initrange = 0.1\n",
    "        self.cls_token_embedding.weight.data.uniform_(-initrange, initrange)\n",
    "        self.linear_head.bias.data.zero_()\n",
    "        self.linear_head.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        cls_token = self.cls_token_embedding(self.cls_token_index)\n",
    "        cls_token = cls_token.expand(x.shape[0], 1, cls_token.shape[1])\n",
    "\n",
    "        x_with_cls = torch.cat((cls_token, x), dim=1)\n",
    "        x_with_pos_encoding = self.positional_encoding(x_with_cls)\n",
    "\n",
    "        encoder_output = self.encoder(x_with_pos_encoding)[:, self.cls_token_index, :]\n",
    "        predictions = self.softmax(self.linear_head(encoder_output))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 250\n",
    "nhead = 2\n",
    "dim_feedforward = 1024\n",
    "dropout = 0\n",
    "num_layers = 15\n",
    "linear_head_size = 1024\n",
    "\n",
    "label_smoothing = 0.0\n",
    "\n",
    "lr = 5e-5\n",
    "n_epochs = 23\n",
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "testing: 100%|██████████| 256/256 [01:56<00:00,  2.19it/s]\n"
     ]
    }
   ],
   "source": [
    "net = THzTransformer(\n",
    "    chunk_size=chunk_size,\n",
    "    nhead=nhead,\n",
    "    dim_feedforward=dim_feedforward,\n",
    "    dropout=dropout,\n",
    "    num_layers=num_layers,\n",
    "    linear_head_size=linear_head_size,\n",
    "    output_size=test_dataset[0][1].shape[0],\n",
    "    device='cuda:0'\n",
    ")\n",
    "net.load_state_dict(torch.load(\"./transformer-detection-scheduler-50epochs.model\"))\n",
    "\n",
    "net.to(device)\n",
    "\n",
    "\n",
    "print(device)\n",
    "\n",
    "\n",
    "pred, y_test = np.empty((0, 25)), np.empty((0, 25))\n",
    "for spectra, target in tqdm(val_loader, desc=\"testing\"):\n",
    "    net.eval()\n",
    "    ans = torch.squeeze(net(spectra), dim=1)\n",
    "    ans = ans.cpu().detach().numpy()\n",
    "    pred = np.append(pred, ans, axis=0)\n",
    "    y_test = np.append(y_test, target.cpu().numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for spectra, target in tqdm(val_loader, desc=\"testing\"):\n",
    "#     ans = net(spectra)\n",
    "#     ans = nn.Softmax()(ans)\n",
    "#     break\n",
    "# ans[5], target[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    mean_absolute_error,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(predictions, targets, epsilon=1e-12):\n",
    "    \"\"\"\n",
    "    Computes cross entropy between targets (encoded as one-hot vectors)\n",
    "    and predictions.\n",
    "    Input: predictions (N, k) ndarray\n",
    "           targets (N, k) ndarray\n",
    "    Returns: scalar\n",
    "    \"\"\"\n",
    "    predictions = np.clip(predictions, epsilon, 1.0 - epsilon)\n",
    "    N = predictions.shape[0]\n",
    "    ce = -np.sum(targets * np.log(predictions + 1e-9)) / N\n",
    "    return ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.010891827321013573\n",
      "MAE: [0.00481605 0.0207287  0.01958805 0.00459834 0.00471008 0.00496477\n",
      " 0.00573083 0.00536138 0.02247059 0.00468851 0.0046347  0.00456631\n",
      " 0.00512989 0.00511868 0.00460899 0.00519681 0.00455206 0.00515543\n",
      " 0.00484662 0.00510472 0.00471393 0.00514337 0.0045685  0.00460082\n",
      " 0.00484011 0.11274925]\n",
      "Cross Entropy: 1.7402779462582796\n"
     ]
    }
   ],
   "source": [
    "# reg transformer-reg.model\n",
    "print(f'MAE: {mean_absolute_error(y_test, pred)}')\n",
    "print(f\"MAE: {mean_absolute_error(y_test, pred, multioutput='raw_values')}\")\n",
    "print(f\"Cross Entropy: {cross_entropy(y_test, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.01067634701709007\n",
      "MAE: [0.00465198 0.0197805  0.01893218 0.0046238  0.00465663 0.00484213\n",
      " 0.00547316 0.00529517 0.02098098 0.00470893 0.00472482 0.00454156\n",
      " 0.00503814 0.00487319 0.00461781 0.00502078 0.0045812  0.00499301\n",
      " 0.00477711 0.00508459 0.00478933 0.00511053 0.00466365 0.00459313\n",
      " 0.00479964 0.11143107]\n",
      "Cross Entropy: 1.6899654094326868\n"
     ]
    }
   ],
   "source": [
    "# reg transformer-reg-scheduler-50epochs.model\n",
    "print(f\"MAE: {mean_absolute_error(y_test, pred)}\")\n",
    "print(f\"MAE: {mean_absolute_error(y_test, pred, multioutput='raw_values')}\")\n",
    "print(f\"Cross Entropy: {cross_entropy(y_test, pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9268807579372814\n",
      "precision: 0.9137851666078969\n",
      "recall: 0.9848391434861555\n",
      "accuracy: 0.5983973747472049\n"
     ]
    }
   ],
   "source": [
    "# detection\n",
    "print(f'F1: {f1_score(y_test, np.where(pred > 0.006, 1, 0), average=\"macro\")}')\n",
    "print(\n",
    "    f'precision: {precision_score(y_test, np.where(pred > 0.006, 1, 0), average=\"macro\")}'\n",
    ")\n",
    "print(f'recall: {recall_score(y_test, np.where(pred > 0.006, 1, 0), average=\"macro\")}')\n",
    "print(f\"accuracy: {accuracy_score(y_test, np.where(pred > 0.006, 1, 0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [0.99953243 0.30591509 0.31370312 0.9996615  0.99946247 0.99711177\n",
      " 0.98478114 0.99535697 0.28260015 0.99530579 0.99514759 0.99582716\n",
      " 0.99973039 0.99986403 0.99918578 0.99478853 0.99952179 0.99993295\n",
      " 0.99979914 0.9992555  0.9941646  0.99756378 0.99850197 0.99858719\n",
      " 0.99932832]\n",
      "recall: [0.98863636 0.99477247 0.99304348 0.98499099 0.98660211 0.98828307\n",
      " 0.97162979 0.97785417 1.         0.97644737 0.9805432  0.98233966\n",
      " 0.98623579 0.98612042 0.9840294  0.98897376 0.98207813 0.98820489\n",
      " 0.98671865 0.983742   0.98126448 0.98483431 0.98001738 0.98441438\n",
      " 0.97920232]\n",
      "F1: [0.99405454 0.46793083 0.47678844 0.99227202 0.99299065 0.99267779\n",
      " 0.97816127 0.98652794 0.44066757 0.9857864  0.98779142 0.98903743\n",
      " 0.99293724 0.99294467 0.99154968 0.99187263 0.99072319 0.99403433\n",
      " 0.99321583 0.99143807 0.98767242 0.99115818 0.98917333 0.99145014\n",
      " 0.98916295]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"precision: {precision_score(y_test, np.where(pred > 0.006, 1, 0), average=None)}\"\n",
    ")\n",
    "\n",
    "print(f\"recall: {recall_score(y_test, np.where(pred > 0.006, 1, 0), average=None)}\")\n",
    "print(f\"F1: {f1_score(y_test, np.where(pred > 0.006, 1, 0), average=None)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1: 0.9356594070858323\n",
      "precision: 0.9243913374570089\n",
      "recall: 0.9580367279301882\n",
      "accuracy: 0.6753920708207731\n"
     ]
    }
   ],
   "source": [
    "# detection transformer-detection-scheduler-50epochs.model\n",
    "print(f'F1: {f1_score(y_test, np.where(pred > 0.07, 1, 0), average=\"macro\")}')\n",
    "print(\n",
    "    f'precision: {precision_score(y_test, np.where(pred > 0.07, 1, 0), average=\"macro\")}'\n",
    ")\n",
    "print(f'recall: {recall_score(y_test, np.where(pred > 0.07, 1, 0), average=\"macro\")}')\n",
    "print(f\"accuracy: {accuracy_score(y_test, np.where(pred > 0.07, 1, 0))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: [1.         0.38522608 0.40905413 0.99986604 1.         0.99793732\n",
      " 0.98940549 0.99866006 0.34934879 0.99773996 0.9973312  0.99633651\n",
      " 0.99960024 0.99993278 1.         0.99668259 0.99986532 1.\n",
      " 0.99980152 1.         0.99607007 0.99845875 0.99993256 0.99920085\n",
      " 0.99933316]\n",
      "recall: [0.99881078 0.71543462 0.71016722 0.99579748 0.99761226 0.99846881\n",
      " 0.97415454 0.98539036 0.66302187 0.9875     0.99262899 0.99309521\n",
      " 0.99760622 0.99738501 0.99772803 0.99780804 0.99664384 0.99840965\n",
      " 0.99854632 0.99686834 0.99000331 0.99545697 0.99097775 0.99509219\n",
      " 0.98631039]\n",
      "F1: [0.99940504 0.50079752 0.51910524 0.99782761 0.9988047  0.998203\n",
      " 0.98172079 0.99198083 0.45759107 0.99259357 0.99497454 0.99471322\n",
      " 0.99860224 0.99865727 0.99886272 0.997245   0.99825198 0.99920419\n",
      " 0.99917353 0.99843171 0.99302743 0.99695561 0.99543502 0.99714229\n",
      " 0.99277907]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"precision: {precision_score(y_test, np.where(pred > 0.07, 1, 0), average=None)}\"\n",
    ")\n",
    "\n",
    "print(f\"recall: {recall_score(y_test, np.where(pred > 0.07, 1, 0), average=None)}\")\n",
    "print(f\"F1: {f1_score(y_test, np.where(pred > 0.07, 1, 0), average=None)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
